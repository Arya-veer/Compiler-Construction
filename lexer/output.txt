tokenize got the input as "declare"
Tokenized DECLARE , sending it for parsing
tokenize got the input as " "
tokenize got the input as "module"
Tokenized MODULE , sending it for parsing
tokenize got the input as " "
tokenize got the input as "mod1"
Tokenized ID , sending it for parsing
tokenize got the input as ";"
Tokenized SEMICOL , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as "<<<"
Tokenized DRIVERDEF , sending it for parsing
tokenize got the input as "driver"
Tokenized DRIVER , sending it for parsing
tokenize got the input as " "
tokenize got the input as "Program"
Tokenized ID , sending it for parsing
tokenize got the input as ">>>"
Tokenized DRIVERENDDEF , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as "start"
Tokenized START , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as " "
tokenize got the input as "declare"
Tokenized DECLARE , sending it for parsing
tokenize got the input as " "
tokenize got the input as " "
tokenize got the input as "v"
Tokenized ID , sending it for parsing
tokenize got the input as ","
Tokenized COMMA , sending it for parsing
tokenize got the input as " "
tokenize got the input as "w"
Tokenized ID , sending it for parsing
tokenize got the input as ","
Tokenized COMMA , sending it for parsing
tokenize got the input as " "
tokenize got the input as "r"
Tokenized ID , sending it for parsing
tokenize got the input as " "
tokenize got the input as ":"
Tokenized COLON , sending it for parsing
tokenize got the input as "integer"
Tokenized INTEGER , sending it for parsing
tokenize got the input as ";"
Tokenized SEMICOL , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as " "
tokenize got the input as "get_value"
Tokenized GET_VALUE , sending it for parsing
tokenize got the input as "("
Tokenized BO , sending it for parsing
tokenize got the input as "v"
Tokenized ID , sending it for parsing
tokenize got the input as ")"
Tokenized BC , sending it for parsing
tokenize got the input as ";"
Tokenized SEMICOL , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as " "
tokenize got the input as "w"
Tokenized ID , sending it for parsing
tokenize got the input as ":="
Tokenized ASSIGNOP , sending it for parsing
tokenize got the input as "5"
Printing as integer => 5
tokenize got the input as ";"
Tokenized SEMICOL , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as " "
tokenize got the input as "declare"
Tokenized DECLARE , sending it for parsing
tokenize got the input as " "
tokenize got the input as "m"
Tokenized ID , sending it for parsing
tokenize got the input as ":"
Tokenized COLON , sending it for parsing
tokenize got the input as "real"
Tokenized REAL , sending it for parsing
tokenize got the input as ";"
Tokenized SEMICOL , sending it for parsing
tokenize got the input as "
"
tokenize got the input as " "
tokenize got the input as "["
Tokenized SQBO , sending it for parsing
tokenize got the input as "r"
Tokenized ID , sending it for parsing
tokenize got the input as ","
Tokenized COMMA , sending it for parsing
tokenize got the input as "m"
Tokenized ID , sending it for parsing
tokenize got the input as "]"
Tokenized SQBC , sending it for parsing
tokenize got the input as " "
tokenize got the input as ":="
Tokenized ASSIGNOP , sending it for parsing
tokenize got the input as " "
tokenize got the input as "use"
Tokenized USE , sending it for parsing
tokenize got the input as " "
tokenize got the input as " "
tokenize got the input as "module"
Tokenized MODULE , sending it for parsing
tokenize got the input as " "
tokenize got the input as "mod1"
Tokenized ID , sending it for parsing
tokenize got the input as " "
tokenize got the input as "with"
Tokenized WITH , sending it for parsing
tokenize got the input as " "
tokenize got the input as "parameters"
Tokenized PARAMETERS , sending it for parsing
tokenize got the input as " "
tokenize got the input as "v"
Tokenized ID , sending it for parsing
tokenize got the input as ","
Tokenized COMMA , sending it for parsing
tokenize got the input as " "
tokenize got the input as "w"
Tokenized ID , sending it for parsing
tokenize got the input as ";"
Tokenized SEMICOL , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as " "
tokenize got the input as "print"
Tokenized PRINT , sending it for parsing
tokenize got the input as "("
Tokenized BO , sending it for parsing
tokenize got the input as "r"
Tokenized ID , sending it for parsing
tokenize got the input as ")"
Tokenized BC , sending it for parsing
tokenize got the input as ";"
Tokenized SEMICOL , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as " "
tokenize got the input as "print"
Tokenized PRINT , sending it for parsing
tokenize got the input as "("
Tokenized BO , sending it for parsing
tokenize got the input as "m"
Tokenized ID , sending it for parsing
tokenize got the input as ")"
Tokenized BC , sending it for parsing
tokenize got the input as ";"
Tokenized SEMICOL , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as "end"
Tokenized END , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
Skipped Comment
tokenize got the input as "
"
tokenize got the input as "<<"
Tokenized DEF , sending it for parsing
tokenize got the input as "module"
Tokenized MODULE , sending it for parsing
tokenize got the input as " "
tokenize got the input as "mod1"
Tokenized ID , sending it for parsing
tokenize got the input as ">>"
Tokenized ENDDEF , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as "takes"
Tokenized TAKES , sending it for parsing
tokenize got the input as " "
tokenize got the input as "input"
Tokenized INPUT , sending it for parsing
tokenize got the input as " "
tokenize got the input as "["
Tokenized SQBO , sending it for parsing
tokenize got the input as "a"
Tokenized ID , sending it for parsing
tokenize got the input as ":"
Tokenized COLON , sending it for parsing
tokenize got the input as " "
tokenize got the input as "integer"
Tokenized INTEGER , sending it for parsing
tokenize got the input as ","
Tokenized COMMA , sending it for parsing
tokenize got the input as " "
tokenize got the input as "b"
Tokenized ID , sending it for parsing
tokenize got the input as ":"
Tokenized COLON , sending it for parsing
tokenize got the input as " "
tokenize got the input as "integer"
Tokenized INTEGER , sending it for parsing
tokenize got the input as "]"
Tokenized SQBC , sending it for parsing
tokenize got the input as ";"
Tokenized SEMICOL , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as "returns"
Tokenized RETURNS , sending it for parsing
tokenize got the input as " "
tokenize got the input as " "
tokenize got the input as "["
Tokenized SQBO , sending it for parsing
tokenize got the input as "x"
Tokenized ID , sending it for parsing
tokenize got the input as ":"
Tokenized COLON , sending it for parsing
tokenize got the input as " "
tokenize got the input as "integer"
Tokenized INTEGER , sending it for parsing
tokenize got the input as ","
Tokenized COMMA , sending it for parsing
tokenize got the input as " "
tokenize got the input as "abc"
Tokenized ID , sending it for parsing
tokenize got the input as ":"
Tokenized COLON , sending it for parsing
tokenize got the input as " "
tokenize got the input as "real"
Tokenized REAL , sending it for parsing
tokenize got the input as "]"
Tokenized SQBC , sending it for parsing
tokenize got the input as ";"
Tokenized SEMICOL , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as "start"
Tokenized START , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as " "
tokenize got the input as "declare"
Tokenized DECLARE , sending it for parsing
tokenize got the input as " "
tokenize got the input as "c"
Tokenized ID , sending it for parsing
tokenize got the input as ":"
Tokenized COLON , sending it for parsing
tokenize got the input as " "
tokenize got the input as "real"
Tokenized REAL , sending it for parsing
tokenize got the input as ";"
Tokenized SEMICOL , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as " "
tokenize got the input as "c"
Tokenized ID , sending it for parsing
tokenize got the input as ":="
Tokenized ASSIGNOP , sending it for parsing
tokenize got the input as "10.4"
Printing as float => 10.400000
tokenize got the input as ";"
Tokenized SEMICOL , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as " "
tokenize got the input as "x"
Tokenized ID , sending it for parsing
tokenize got the input as ":="
Tokenized ASSIGNOP , sending it for parsing
tokenize got the input as "a"
Tokenized ID , sending it for parsing
tokenize got the input as "+"
Tokenized PLUS , sending it for parsing
tokenize got the input as "b"
Tokenized ID , sending it for parsing
Lexical Error occured at line 19, "#" ,  invalid character '#'
tokenize got the input as "10"
Printing as integer => 10
tokenize got the input as ";"
Tokenized SEMICOL , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as " "
tokenize got the input as "abc"
Tokenized ID , sending it for parsing
tokenize got the input as ":="
Tokenized ASSIGNOP , sending it for parsing
tokenize got the input as "b"
Tokenized ID , sending it for parsing
tokenize got the input as "/"
Tokenized DIV , sending it for parsing
tokenize got the input as "5"
Printing as integer => 5
tokenize got the input as "+"
Tokenized PLUS , sending it for parsing
tokenize got the input as "c"
Tokenized ID , sending it for parsing
tokenize got the input as ";"
Tokenized SEMICOL , sending it for parsing
tokenize got the input as " "
tokenize got the input as "
"
tokenize got the input as "end"
Tokenized END , sending it for parsing
Tokenized EOF , sending it for parsing
finish reading
